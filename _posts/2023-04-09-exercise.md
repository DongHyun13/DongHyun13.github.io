---
layout: single
title:  "2019250035 이동현 "
---

<head>
  <style>
    table.dataframe {
      white-space: normal;
      width: 100%;
      height: 240px;
      display: block;
      overflow: auto;
      font-family: Arial, sans-serif;
      font-size: 0.9rem;
      line-height: 20px;
      text-align: center;
      border: 0px !important;
    }

    table.dataframe th {
      text-align: center;
      font-weight: bold;
      padding: 8px;
    }

    table.dataframe td {
      text-align: center;
      padding: 8px;
    }

    table.dataframe tr:hover {
      background: #b8d1f3; 
    }

    .output_prompt {
      overflow: auto;
      font-size: 0.9rem;
      line-height: 1.45;
      border-radius: 0.3rem;
      -webkit-overflow-scrolling: touch;
      padding: 0.8rem;
      margin-top: 0;
      margin-bottom: 15px;
      font: 1rem Consolas, "Liberation Mono", Menlo, Courier, monospace;
      color: $code-text-color;
      border: solid 1px $border-color;
      border-radius: 0.3rem;
      word-break: normal;
      white-space: pre;
    }

  .dataframe tbody tr th:only-of-type {
      vertical-align: middle;
  }

  .dataframe tbody tr th {
      vertical-align: top;
  }

  .dataframe thead th {
      text-align: center !important;
      padding: 8px;
  }

  .page__content p {
      margin: 0 0 0px !important;
  }

  .page__content p > strong {
    font-size: 0.8rem !important;
  }

  </style>
</head>



```python
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# 데이터 불러오기
train = pd.read_csv('/kaggle/input/titanic/train.csv')
test = pd.read_csv('/kaggle/input/titanic/test.csv')

# 불필요한 변수 제거
train = train.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'Embarked'], axis=1)
test = test.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'Embarked'], axis=1)

# 결측치 처리
train = train.dropna()
test = test.fillna(0)

# 범주형 변수 더미 변수화
train = pd.get_dummies(train, columns=['Sex'])
test = pd.get_dummies(test, columns=['Sex'])

# 데이터 스케일링
sc = StandardScaler()
train[['Age', 'Fare']] = sc.fit_transform(train[['Age', 'Fare']])
test[['Age', 'Fare']] = sc.transform(test[['Age', 'Fare']])

# 학습용 데이터와 테스트용 데이터로 분리
X_train = train.drop('Survived', axis=1)
y_train = train['Survived']
X_test = test.copy()

# 로지스틱 회귀 모델 학습
clf = LogisticRegression()
clf.fit(X_train, y_train)

# 테스트 데이터 예측
y_pred = clf.predict(X_test)

# 결과 출력
submission = pd.DataFrame({
    "PassengerId": test.index + 892,
    "Survived": y_pred
})

submission.to_csv("submission.csv", index=False)

# 실제 답
y_true = submission['Survived']

# 정확도 계산
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_true, y_pred)
print("Accuracy: {:.2f}%".format(accuracy*100))



```

<pre>
/kaggle/input/titanic/train.csv
/kaggle/input/titanic/test.csv
/kaggle/input/titanic/gender_submission.csv
Accuracy: 100.00%
</pre>

```
<pre>
1. Pandas를 사용하여 학습용 데이터(train)와 테스트용 데이터(test)를 불러온다.

2. 불필요한 변수(PassengerId, Name, Ticket, Cabin, Embarked)를 제거한다.

3. 결측치를 처리한다. 학습용 데이터에서는 dropna() 함수를 사용하여 결측치가 있는 행을 삭제하고, 테스트용 데이터에서는 fillna() 함수를 사용하여 Age와 Fare 변수의 결측치를 0으로 채운다.

4. 범주형 변수(Sex)를 더미 변수화한다.

5. 데이터 스케일링을 수행한다. StandardScaler를 사용하여 Age와 Fare 변수를 스케일링한다.

6. 학습용 데이터(X_train)와 레이블(y_train), 테스트용 데이터(X_test)를 분리한다.

7. 로지스틱 회귀 모델(LogisticRegression)을 학습한다.

8. 학습된 모델을 사용하여 테스트 데이터에 대한 예측(y_pred)을 수행한다.

9. 예측 결과를 submission.csv 파일에 저장한다.

10. sklearn.metrics 모듈의 accuracy_score 함수를 사용하여 정확도(accuracy)를 계산한다.

11. 계산된 정확도를 출력한다.
</pre>
